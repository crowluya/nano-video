/**
 * AI Edit Suggestion API Route
 * 
 * POST /api/ai/edit-suggest
 * - Takes user's description and assets
 * - Returns an EditProject configuration generated by AI
 */

import { createAIModel } from "@/lib/ai-model-factory";
import { apiResponse } from "@/lib/api-response";
import { generateObject } from "ai";
import { z } from "zod";

// Input schema for edit suggestion request
const inputSchema = z.object({
  description: z.string().min(1, "Description is required"),
  assets: z.array(
    z.object({
      id: z.string(),
      type: z.enum(["video", "image", "audio"]),
      name: z.string(),
      url: z.string(),
      duration: z.number().optional(),
      width: z.number().optional(),
      height: z.number().optional(),
    })
  ),
  style: z.enum(["cinematic", "fast-paced", "minimal", "dynamic"]).optional(),
  targetDuration: z.number().optional(),
  resolution: z.enum(["1080p", "720p", "480p", "vertical-1080p", "square"]).optional(),
});

// Output schema for AI to generate
const editProjectSchema = z.object({
  name: z.string(),
  timeline: z.array(
    z.object({
      id: z.string(),
      type: z.enum(["video", "image", "audio", "text"]),
      src: z.string().optional(),
      text: z.string().optional(),
      startTime: z.number(),
      duration: z.number(),
      layer: z.number(),
      // Video/Audio specific
      volume: z.number().optional(),
      trimStart: z.number().optional(),
      // Image specific
      fit: z.enum(["cover", "contain", "fill"]).optional(),
      // Text specific
      fontSize: z.number().optional(),
      fontFamily: z.string().optional(),
      color: z.string().optional(),
      position: z.object({
        x: z.number(),
        y: z.number(),
      }).optional(),
      animation: z.enum(["none", "fade-in", "fade-out", "slide-in", "typewriter", "bounce", "scale-in"]).optional(),
    })
  ),
  duration: z.number(),
  fps: z.number(),
  resolution: z.object({
    width: z.number(),
    height: z.number(),
  }),
  backgroundColor: z.string().optional(),
  explanation: z.string(),
});

export async function POST(req: Request) {
  try {
    // Use OpenRouter for AI
    const apiKey = process.env.OPENROUTER_API_KEY;
    if (!apiKey) {
      return apiResponse.serverError("Server configuration error: Missing OpenRouter API Key");
    }

    const rawBody = await req.json();
    const validationResult = inputSchema.safeParse(rawBody);

    if (!validationResult.success) {
      return apiResponse.badRequest(
        `Invalid input: ${validationResult.error.errors.map(e => `${e.path.join('.')}: ${e.message}`).join(', ')}`
      );
    }

    const { description, assets, style, targetDuration, resolution } = validationResult.data;

    // Build the prompt
    const assetList = assets.map(a => 
      `- ${a.name} (${a.type}${a.duration ? `, ${a.duration}s` : ''}): ${a.url}`
    ).join('\n');

    const resolutionMap: Record<string, { width: number; height: number }> = {
      "1080p": { width: 1920, height: 1080 },
      "720p": { width: 1280, height: 720 },
      "480p": { width: 854, height: 480 },
      "vertical-1080p": { width: 1080, height: 1920 },
      "square": { width: 1080, height: 1080 },
    };

    const targetRes = resolutionMap[resolution || "1080p"];

    const systemPrompt = `You are an expert video editor AI assistant. Your task is to create a video editing timeline based on the user's description and available assets.

Guidelines:
- Create a cohesive video that flows naturally
- Use appropriate timing for transitions (each visual should be visible for at least 2-3 seconds)
- Layer audio tracks below visual tracks (negative layer numbers)
- Add text overlays sparingly for emphasis
- Consider the style requested: ${style || 'balanced'}
- Target duration: ${targetDuration ? `${targetDuration} seconds` : 'automatic based on content'}

For text tracks:
- Use them for titles, captions, or emphasis
- Position: x and y are percentages (0-100)
- Common animations: fade-in for subtitles, scale-in for titles

For video/image tracks:
- Use 'cover' fit for full-screen backgrounds
- Layer 0 or higher for visuals

For audio tracks:
- Layer should be negative (e.g., -1)
- Set volume between 0.3-0.8 for background music
- Set volume at 1.0 for main audio`;

    const userPrompt = `Create a video edit for this description:
"${description}"

Available assets:
${assetList}

Output resolution: ${targetRes.width}x${targetRes.height}
FPS: 30

Create a timeline that brings this vision to life. Include an explanation of your editing choices.`;

    // Use OpenRouter model
    const model = createAIModel("openrouter", "openai/gpt-4o-mini");

    const result = await generateObject({
      model,
      schema: editProjectSchema,
      system: systemPrompt,
      prompt: userPrompt,
    });

    // Post-process: ensure track IDs are unique and valid
    const project = {
      ...result.object,
      timeline: result.object.timeline.map((track, index) => ({
        ...track,
        id: track.id || `track-${index}-${Date.now()}`,
        src: track.type !== 'text' ? track.src : undefined,
        text: track.type === 'text' ? track.text : undefined,
      })),
    };

    return apiResponse.success({
      project: {
        name: project.name,
        timeline: project.timeline,
        duration: project.duration,
        fps: project.fps,
        resolution: project.resolution,
        backgroundColor: project.backgroundColor || "#000000",
      },
      explanation: project.explanation,
    });

  } catch (error: unknown) {
    console.error("AI edit suggestion failed:", error);
    const errorMessage = error instanceof Error ? error.message : "Failed to generate edit suggestion";
    
    if (errorMessage.includes("API key") || errorMessage.includes("authentication")) {
      return apiResponse.unauthorized("Authentication error with AI provider");
    }
    
    return apiResponse.serverError(errorMessage);
  }
}

